{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T14:54:11.565311Z",
     "start_time": "2019-08-18T14:54:10.903810Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T14:54:12.301966Z",
     "start_time": "2019-08-18T14:54:12.289810Z"
    }
   },
   "outputs": [],
   "source": [
    "def showImg(img, title = ''):\n",
    "    plt.figure(figsize = (20,15));\n",
    "    plt.title(title)\n",
    "    plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))\n",
    "\n",
    "def showGrayScaleImg(img, title = ''):\n",
    "    plt.figure(figsize = (20,15));\n",
    "    plt.title(title)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "\n",
    "all_contours = -1\n",
    "green = (0,255,0)\n",
    "thickness = 2\n",
    "\n",
    "new_img = cv2.UMat(cv2.IMREAD_COLOR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Template Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T19:07:05.785979Z",
     "start_time": "2019-08-15T19:07:04.391973Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('img/WandoScene.jpg')\n",
    "image = cv2.imread('img/WaldoScene1.jpg')\n",
    "\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Load Template image\n",
    "template = cv2.imread('img/waldo.jpg',0)\n",
    "\n",
    "\n",
    "result = cv2.matchTemplate(gray, template, cv2.TM_CCOEFF)\n",
    "min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "\n",
    "#Create Bounding Box\n",
    "top_left = max_loc\n",
    "bottom_right = (top_left[0] + 50, top_left[1] + 50)\n",
    "cv2.rectangle(image, top_left, bottom_right, (0,255,0), 3)\n",
    "showImg(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T13:58:25.062437Z",
     "start_time": "2019-08-16T13:58:24.522435Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('img/chess.jpg')\n",
    "image = cv2.imread('img/corners.png')\n",
    "\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# The cornerHarris function requires the array datatype to be float32\n",
    "gray = np.float32(gray)\n",
    "\n",
    "harris_corners = cv2.cornerHarris(gray, 3, 3, 0.05)\n",
    "\n",
    "#We use dilation of the corner points to enlarge them\\\n",
    "kernel = np.ones((7,7),np.uint8)\n",
    "harris_corners = cv2.dilate(harris_corners, kernel, iterations = 1)\n",
    "\n",
    "# Threshold for an optimal value, it may vary depending on the image.\n",
    "image[harris_corners > 0.025 * harris_corners.max() ] = [255, 127, 127]\n",
    "\n",
    "showImg(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T17:39:30.546123Z",
     "start_time": "2019-08-16T17:39:30.022620Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('img/chess.jpg')\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# We specific the top 50 corners\n",
    "corners = cv2.goodFeaturesToTrack(gray, 60, 0.1, 50)\n",
    "#corners = cv2.goodFeaturesToTrack(gray, 60, 0.01, 50)\n",
    "\n",
    "\n",
    "for corner in corners:\n",
    "    x, y = corner[0]\n",
    "    x = int(x)\n",
    "    y = int(y)\n",
    "    cv2.rectangle(img,(x-5,y-5),(x+5,y+5),(0,255,0), -1)\n",
    "    \n",
    "showImg(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-17T17:04:22.245921Z",
     "start_time": "2019-08-17T17:04:22.129408Z"
    }
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('img/1.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#Create SIFT Feature Detector object\n",
    "#sift = cv2.SIFT()\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "\n",
    "#Detect key points\n",
    "keypoints = sift.detect(gray, None)\n",
    "print(\"Number of keypoints Detected: \", len(keypoints))\n",
    "\n",
    "# Draw rich key points on input image\n",
    "image = cv2.drawKeypoints(image, keypoints,None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "showImg(image,'Feature Method - SIFT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SURF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-17T17:07:08.054889Z",
     "start_time": "2019-08-17T17:07:07.977887Z"
    }
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('img/1.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#Create SURF Feature Detector object\n",
    "#surf = cv2.SURF(400)\n",
    "surf = cv2.xfeatures2d.SURF_create()\n",
    "\n",
    "\n",
    "# Only features, whose hessian is larger than hessianThreshold are retained by the detector\n",
    "surf.hessianThreshold = 500\n",
    "keypoints, descriptors = surf.detectAndCompute(gray, None)\n",
    "print(\"Number of keypoints Detected: \", len(keypoints))\n",
    "\n",
    "# Draw rich key points on input image\n",
    "image = cv2.drawKeypoints(image, keypoints, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T14:05:33.564565Z",
     "start_time": "2019-08-18T14:05:31.917064Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of keypoints Detected:  1993\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread('img/1.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Create FAST Detector object\n",
    "fast = cv2.FastFeatureDetector_create(40)\n",
    "\n",
    "# Obtain Key points, by default non max suppression is On\n",
    "# to turn off set fast.setBool('nonmaxSuppression', False)\n",
    "keypoints = fast.detect(gray, None)\n",
    "print(\"Number of keypoints Detected: \", len(keypoints))\n",
    "\n",
    "# Draw rich keypoints on input image\n",
    "image = cv2.drawKeypoints(image, keypoints, new_img, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "#\n",
    "\n",
    "cv2.imshow('Feature Method - FAST', image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "#showImg(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T14:05:37.853586Z",
     "start_time": "2019-08-18T14:05:35.536563Z"
    }
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('img/2.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Create FAST Detector object\n",
    "fast = cv2.FastFeatureDetector_create(40)\n",
    "\n",
    "# Obtain Key points, by default non max suppression is On\n",
    "# to turn off set fast.setBool('nonmaxSuppression', False)\n",
    "keypoints = fast.detect(gray, None)\n",
    "print(\"Number of keypoints Detected: \", len(keypoints))\n",
    "\n",
    "# Draw rich keypoints on input image\n",
    "image = cv2.drawKeypoints(image, keypoints, new_img, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "#cv2.imshow('Feature Method - FAST', image)\n",
    "#cv2.waitKey()\n",
    "#cv2.destroyAllWindows()\n",
    "showImg(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ORB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T14:06:19.960593Z",
     "start_time": "2019-08-18T14:06:16.077566Z"
    }
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('img/1.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Create ORB object, we can specify the number of key points we desire\n",
    "orb = cv2.ORB_create()\n",
    "\n",
    "# Determine key points\n",
    "keypoints = orb.detect(gray, None)\n",
    "\n",
    "# Obtain the descriptors\n",
    "keypoints, descriptors = orb.compute(gray, keypoints)\n",
    "print(\"Number of keypoints Detected: \", len(keypoints))\n",
    "\n",
    "# Draw rich keypoints on input image\n",
    "new_img = cv2.UMat(cv2.IMREAD_COLOR)\n",
    "\n",
    "image = cv2.drawKeypoints(image, keypoints,new_img,flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "\n",
    "    \n",
    "cv2.imshow('Feature Method - ORB', image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T14:06:42.957105Z",
     "start_time": "2019-08-18T14:06:39.853567Z"
    }
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('img/2.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Create ORB object, we can specify the number of key points we desire\n",
    "orb = cv2.ORB_create()\n",
    "\n",
    "# Determine key points\n",
    "keypoints = orb.detect(gray, None)\n",
    "\n",
    "# Obtain the descriptors\n",
    "keypoints, descriptors = orb.compute(gray, keypoints)\n",
    "print(\"Number of keypoints Detected: \", len(keypoints))\n",
    "\n",
    "# Draw rich keypoints on input image\n",
    "new_img = cv2.UMat(cv2.IMREAD_COLOR)\n",
    "\n",
    "image = cv2.drawKeypoints(image, keypoints,new_img,flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "\n",
    "    \n",
    "cv2.imshow('Feature Method - ORB', image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T14:54:18.160810Z",
     "start_time": "2019-08-18T14:54:18.145810Z"
    }
   },
   "outputs": [],
   "source": [
    "def ORB_detector(new_image, image_template):\n",
    "    # Function that compares input image to template\n",
    "    # It then returns the number of ORB matches between them\n",
    "    \n",
    "    image1 = cv2.cvtColor(new_image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #showImg(image1)\n",
    "    \n",
    "    # Create ORB detector with 1000 keypoints with a scaling pyramid factor of 1.2\n",
    "    orb = cv2.ORB_create(1000, 1.2)\n",
    "    \n",
    "    # Detect keypoints of original image\n",
    "    (kp1, des1) = orb.detectAndCompute(image1, None)\n",
    "\n",
    "    # Detect keypoints of rotated image\n",
    "    (kp2, des2) = orb.detectAndCompute(image_template, None)\n",
    "\n",
    "    # Create matcher     \n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "    # Do matching\n",
    "    matches = bf.match(des1,des2)\n",
    "\n",
    "    # Sort the matches based on distance.  Least distance\n",
    "    # is better\n",
    "    matches = sorted(matches, key=lambda val: val.distance)\n",
    "    \n",
    "    if len(matches) > 210:\n",
    "        matches_img = cv2.drawMatches(image1,kp1,image_template,kp2,matches[:20],None)\n",
    "        cv2.imwrite('orbMatches.jpg',matches_img)\n",
    "\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T14:54:20.064814Z",
     "start_time": "2019-08-18T14:54:19.023309Z"
    }
   },
   "outputs": [],
   "source": [
    "image_template = cv2.imread('img/skittles.jpg', 0) \n",
    "showImg(image_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T14:55:31.789310Z",
     "start_time": "2019-08-18T14:55:22.304314Z"
    }
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Load our image template, this is our reference image\n",
    "image_template = cv2.imread('img/skittles.jpg', 0) \n",
    "\n",
    "while True:\n",
    "\n",
    "    # Get webcam images\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Get height and width of webcam frame\n",
    "    height, width = frame.shape[:2]\n",
    "\n",
    "    # Define ROI Box Dimensions (Note some of these things should be outside the loop)\n",
    "    top_left_x = width // 3\n",
    "    top_left_y = (height // 2) + (height // 4)\n",
    "    bottom_right_x = (width // 3) * 2\n",
    "    bottom_right_y = (height // 2) - (height // 4)\n",
    "    \n",
    "    # Draw rectangular window for our region of interest\n",
    "    cv2.rectangle(frame, (top_left_x,top_left_y), (bottom_right_x,bottom_right_y), (0,255,0), 3)\n",
    "    #cv2.rectangle(img_copy,(240,220),(550,510),(0,255,0),2);\n",
    "    \n",
    "    # Crop window of observation we defined above\n",
    "    cropped = frame[bottom_right_y:top_left_y , top_left_x:bottom_right_x]\n",
    "\n",
    "    # Flip frame orientation horizontally\n",
    "    frame = cv2.flip(frame,1)\n",
    "    \n",
    "    # Get number of ORB matches \n",
    "    matches = ORB_detector(cropped, image_template)\n",
    "    \n",
    "    # Display status string showing the current no. of matches \n",
    "    output_string = \"Matches = \" + str(len(matches))\n",
    "    cv2.putText(frame, output_string, (50,450), cv2.FONT_HERSHEY_COMPLEX, 2, (250,0,150), 2)\n",
    "    \n",
    "    # Our threshold to indicate object deteciton\n",
    "    # For new images or lightening conditions you may need to experiment a bit     \n",
    "    threshold = 210\n",
    "    \n",
    "    # If matches exceed our threshold then object has been detected\n",
    "    if len(matches) > threshold:\n",
    "        cv2.rectangle(frame, (top_left_x,top_left_y), (bottom_right_x,bottom_right_y), (0,255,0), 3)\n",
    "        cv2.putText(frame,'Object Found',(50,50), cv2.FONT_HERSHEY_COMPLEX, 2 ,(0,255,0), 2)        \n",
    "    \n",
    "    cv2.imshow('Object Detector using ORB', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HAAR Cascades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T15:56:04.680168Z",
     "start_time": "2019-08-18T15:55:55.826701Z"
    }
   },
   "outputs": [],
   "source": [
    "face_classifier = cv2.CascadeClassifier('Haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Load our image then convert it to grayscale\n",
    "image = cv2.imread('img/people1.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Our classifier returns the ROI of the detected face as a tuple\n",
    "# It stores the top left coordinate and the bottom right coordiantes\n",
    "faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "# When no faces detected, face_classifier returns and empty tuple\n",
    "if faces is ():\n",
    "    print(\"No faces found\")\n",
    "\n",
    "# We iterate through our faces array and draw a rectangle\n",
    "# over each face in faces\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(image, (x,y), (x+w,y+h), (127,0,255), 2)\n",
    "    #cv2.imshow('Face Detection', image)\n",
    "    showImg(image)\n",
    "    \n",
    "#cv2.waitKey(0)    \n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T16:00:03.162235Z",
     "start_time": "2019-08-18T15:59:42.563731Z"
    }
   },
   "outputs": [],
   "source": [
    "face_classifier = cv2.CascadeClassifier('Haarcascades/haarcascade_frontalface_default.xml')\n",
    "eye_classifier = cv2.CascadeClassifier('Haarcascades/haarcascade_eye.xml')\n",
    "\n",
    "def face_detector(img, size=0.5):\n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return img\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        x = x - 50\n",
    "        w = w + 50\n",
    "        y = y - 50\n",
    "        h = h + 50\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]\n",
    "        eyes = eye_classifier.detectMultiScale(roi_gray)\n",
    "        \n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,0,255),2) \n",
    "            \n",
    "    roi_color = cv2.flip(roi_color,1)\n",
    "    return roi_color\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imshow('Our Face Extractor', face_detector(frame))\n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Mini Projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Level 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Students detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1. Create an object detector capable of identifying at least 2 of your class mates (the more the better) in an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Cars detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1. Create a classifier to detect cars in an image\n",
    "1. If at least one car was detected write Car Detected (in Green) on top of the image, otherwise write No car detected (in Red)\n",
    "1. Save the image to disk\n",
    "1. Show the image result inside the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Level 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Students detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1. Now make it work live with a webcam, if a person is detected write the name of the person on top of the image\n",
    "1. Save the image to disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Cars detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1. Make it work with a video0\n",
    "1. Put a bounding box around the cars detected\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Level 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Students detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1. Show on screen how many persons are currently in the room\n",
    "1. List the name of the persons in the room  \n",
    "1. If a person was detected but does not match with any student add a person to the room and to the list as 'Unknown Person'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Cars detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1. Get a higher resolution video and extract the car plates and save them to disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Level 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Students detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1. When a person leaves decrease the number of persons in the room\n",
    "1. When a person arrives increase the number of persons in the room\n",
    "1. Update the list of names as the persons arrive and leave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
